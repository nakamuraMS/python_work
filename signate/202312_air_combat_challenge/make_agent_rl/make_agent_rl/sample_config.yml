
save_dir: ./results/Multi

env_args:
    userModelID: Sample
    userModuleID: Test
    modelargs: args.json
    env: sample
    env_config:
        config: 
        - ./configs/R5_contest_mission_config.json
        - ./configs/R5_contest_learning_config_M.json
        - ./configs/R5_contest_asset_models.json
        - ./configs/R5_contest_agent_ruler_reward_models.json
        - Manager:
            ViewerType: None
            Callbacks: {}
            Loggers: {}

policy_config:
    Learner:
        multi_port: true
        active_limit: 50
        is_internal: false
        populate:
            first_population: 1000
            interval: 1000
            on_start: false
        rating_initial: 1500
        rating_fixed: false
        initial_weight: null
        model_class: R5TorchNNSampleForHandyRL
        model_config:
            actionDistributionClassGetter: actionDistributionClassGetter
            use_lstm: false
            lstm_cell_size: 256
            lstm_num_layers: 1
            lstm_dropout: 0.2
            pos_conv:
                layers:
                    - ["Conv2d",{"kernel_size": 7,"out_channels": 32,"padding": 3,"stride": 2}]
                    - ["BatchNorm2d",{}]
                    - ["ReLU",{}]
                    - ["ResidualBlock",{
                        "layers":[
                            ["Conv2d",{"kernel_size": 3,"out_channels": 32,"padding": 1}],
                            ["BatchNorm2d",{}],
                            ["ReLU",{}],
                            ["Conv2d",{"kernel_size": 3,"out_channels": 32,"padding": 1}],
                            ["BatchNorm2d",{}]
                        ]}]
                    - ["ReLU",{}]
                    - ["Conv2d",{"kernel_size": 4,"out_channels": 64,"padding": 1,"stride": 2}]
                    - ["BatchNorm2d",{}]
                    - ["ReLU",{}]
                    - ["ResidualBlock",{
                        "layers":[
                            ["Conv2d",{"kernel_size": 3,"out_channels": 64,"padding": 1}],
                            ["BatchNorm2d",{}],
                            ["ReLU",{}],
                            ["Conv2d",{"kernel_size": 3,"out_channels": 64,"padding": 1}],
                            ["BatchNorm2d",{}]
                        ]}]
                    - ["ReLU",{}]
                    - ["Conv2d",{"kernel_size": 4,"out_channels": 128,"padding": 1,"stride": 2}]
                    - ["BatchNorm2d",{}]
                    - ["ReLU",{}]
                    - ["ResidualBlock",{
                        "layers":[
                            ["Conv2d",{"kernel_size": 3,"out_channels": 128,"padding": 1}],
                            ["BatchNorm2d",{}],
                            ["ReLU",{}],
                            ["Conv2d",{"kernel_size": 3,"out_channels": 128,"padding": 1}],
                            ["BatchNorm2d",{}]
                        ]}]
                    - ["ReLU",{}]
                    - ["AdaptiveAvgPool2d",{"output_size": 1}]
                    - ["Flatten",{}]
            dense:
                layers:
                    - ["Linear",{"out_features": 128}]
                    - ["ReLU",{}]
                    - ["ResidualBlock",{
                        "layers":[
                            ["Linear",{"out_features": 128}],
                            ["BatchNorm1d",{}]
                        ]}]
                    - ["ReLU",{}]
                    - ["ResidualBlock",{
                        "layers":[
                            ["Linear",{"out_features": 128}],
                            ["BatchNorm1d",{}]
                        ]}]
            merge:
                layers:
                    - ["ReLU",{}]
            value:
                layers:
                    - ["Linear",{"out_features": 64}]
                    - ["ReLU",{}]
                    - ["Linear",{"out_features": 64}]
                    - ["ReLU",{}]
            return:
                layers:
                    - ["Linear",{"out_features": 64}]
                    - ["ReLU",{}]
                    - ["Linear",{"out_features": 64}]
                    - ["ReLU",{}]
            action:
                layers:
                    - ["Linear",{"out_features": 128}]
                    - ["ReLU",{}]
                    - ["Linear",{"out_features": 128}]
                    - ["ReLU",{}]
    Initial:
        multi_port: false
        active_limit: null
        is_internal: true
        populate: null
        rating_initial: 1500
        rating_fixed: true
        initial_weight: null
        model_class: DummyInternalModel
        model_config: {}
# 模倣学習(Behavior cloning又はOffline RL)を実施する場合はコメントアウトを外す
# R5_contest_learning_config_M.jsonにおいて、所望のExpertWrapperのalias名と一致していることを確認すること
#    Expert:
#        multi_port: true
#        active_limit: null
#        is_internal: true
#        populate: null
#        rating_initial: 1500
#        rating_fixed: false
#        initial_weight: null
#        model_class: DummyInternalModel
#        model_config: {}

train_args:
    name: Learner
    match_maker_class: TwoTeamCombatMatchMaker
    match_monitor_class: TwoTeamCombatMatchMonitor
    turn_based_training: false
    observation: false
    gamma: 0.95
    forward_steps: 32
    burn_in_steps: 4  # for RNNs
    compress_steps: 4
    entropy_regularization: 4.0e-3
    entropy_regularization_decay: 0.1
    separate_policy_gradients: false
    exploration_config:
        use_exploration: true
        only_one_explorer_per_policy: false
        eps_start: 0.4
        eps_end: 0.4
        eps_decay: -1
        alpha: 7.0
        cycle: 16
    update_episodes: 10
    batch_size: 128
    minimum_episodes: 10
    maximum_episodes: 300
    epochs: 5
    num_batchers: 4
    eval_rate: 0.1
    worker:
        num_parallel: 12
    lambda: 0.7
    policy_target: UPGO # 'UPGO' 'VTRACE' 'TD' 'MC'
    value_target: TD # 'VTRACE' 'TD' 'MC'
    seed: 0
    policy_to_train: Learner
    policy_to_imitate: [] # ["Expert"] #摸倣学習を実施する際は教師役のpolicy名を与える
    imitation_beta: 0.6
    imitation_kl_threshold: 1.0
    imitation_loss_scale: 1.0
    imitation_loss_threshold: 1.0
    deterministic:
        g: 0.1
        e: 0.1

worker_args:
    server_address: ''
    num_parallel: 12

match_maker_args:
    seed: 12345
    match_config:
        #expert_ratio: 0.2 #模倣学習を行う際のみ指定する。
        warm_up_episodes: 1000
        initial_state_lower:
            pos: [-10000.0,20000.0,-12000.0]
            vel: 260.0
            heading: 225.0
        initial_state_upper:
            pos: [10000.0,25000.0,-6000.0]
            vel: 280.0
            heading: 315.0
